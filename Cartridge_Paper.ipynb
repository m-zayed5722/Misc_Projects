{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkXK2qQK9+kfp7t9SJYPd/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-zayed5722/Misc_Projects/blob/main/Cartridge_Paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V62MZgSYRALW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, DiceLoss, JaccardLoss\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Data Acquisition and Preprocessing"
      ],
      "metadata": {
        "id": "WP3jHyaKQ6b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Assuming image and mask filenames are related (e.g., 'image_001.jpg' and 'mask_001.jpg')\n",
        "# Load images and masks using OpenCV\n",
        "images = []\n",
        "masks = []\n",
        "\n",
        "# Convert lists to NumPy arrays for further processing\n",
        "images = np.array(images)\n",
        "masks = np.array(masks)"
      ],
      "metadata": {
        "id": "P9lwPyOuRe1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "XYwzHo8PRgWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing: split the data into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further split for validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "1BUzfvizRgZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n"
      ],
      "metadata": {
        "id": "53wJyO8IRgco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate augmented images and masks using the flow method\n",
        "augmented_data = datagen.flow(np.array(X_train), np.array(y_train), batch_size=len(X_train), shuffle=False)\n",
        "\n",
        "# Extract augmented images and masks from the generated batches\n",
        "augmented_images, augmented_masks = augmented_data.next()\n",
        "\n",
        "# Update training set with augmented data\n",
        "X_train = np.concatenate([X_train, augmented_images])\n",
        "y_train = np.concatenate([y_train, augmented_masks])"
      ],
      "metadata": {
        "id": "KdRSwfcJRgk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few original and augmented images and masks\n",
        "#..."
      ],
      "metadata": {
        "id": "AZll4DWnRgrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8rbzyIqORfX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2: Implement the U-net model and training process"
      ],
      "metadata": {
        "id": "8nwOQotXRIu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define U-Net architecture for 2D images\n",
        "def u_net_2d(input_size):\n",
        "    inputs_2d = keras.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1_2d = Conv2D(32, (3, 3), activation='relu')(inputs_2d)\n",
        "    pool1_2d = MaxPooling2D((2, 2))(conv1_2d)\n",
        "\n",
        "    # Downsampling\n",
        "    conv2_2d = Conv2D(64, (1, 1), activation='elu', padding='same', dilation_rate=1)(pool1_2d)\n",
        "    pool2_2d = MaxPooling1D(2)(conv2_2d)\n",
        "\n",
        "    conv3_2d = Conv2D(128, (1, 1), activation=\"elu\", padding='same', dilation_rate=2)(pool2_2d)\n",
        "    pool3_2d = MaxPooling2D()(conv3_2d)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4_2d = Conv2D(256, (1, 1), activation=\"elu\", padding='same')(pool3_2d)\n",
        "\n",
        "    up1_2d = UpSampling2D((2, 2))(conv4_2d)\n",
        "    concat1_2d = concatenate([up1_2d, conv3_2d])\n",
        "    conv5_2d = Conv2D(128, (1, 1), activation=\"elu\")(concat1_2d)\n",
        "\n",
        "    up2_2d = UpSampling2D((2, 2))(conv5_2d)\n",
        "    concat2_2d = concatenate([up2_2d, conv2_2d])\n",
        "    conv6_2d = Conv2D(64, (1, 1), activation=\"elu\")(concat2_2d)\n",
        "\n",
        "    outputs_2d = conv6_2d\n",
        "\n",
        "    u_net_2d_model = Model(inputs=[inputs_2d], outputs=[outputs_2d])\n",
        "    return u_net_2d_model"
      ],
      "metadata": {
        "id": "xBIcrwpeR_yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to train the U-Net\n",
        "def train_u_net(train_data_dir, train_mask_dir, validation_data_dir=None, validation_mask_dir=None):\n",
        "    # Load and preprocess the data\n",
        "    train_img_generator = ImageDataGenerator(rescale=1./255)\n",
        "    train_mask_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Training data generator parameters\n",
        "    train_data_gen_args = dict(rotation_range=90, width_shift_range=0.1, height_shift_range=0.1, shear_range=0, zoom_range=0)\n",
        "\n",
        "    # Compile the model\n",
        "    model = u_net_2d(input_size=(height, width, channels))\n",
        "    model.summary()\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    steps_per_epoch = 10\n",
        "    epochs = 100\n",
        "\n",
        "    if validation_data_dir:\n",
        "        val_img_generator = ImageDataGenerator(rescale=1./255)\n",
        "        val_mask_generator = ImageDataGenerator(rescale=1./255)\n",
        "        validation_data_gen_args = dict()\n",
        "        val_data_generator = val_img_generator.flow_from_directory(\n",
        "            validation_data_dir,\n",
        "            class_mode=None,\n",
        "            color_mode='rgb',\n",
        "            target_size=(height, width),\n",
        "            batch_size=batch_size,\n",
        "            seed=42\n",
        "        )\n",
        "        validation_steps = len(val_data_generator)\n",
        "    else:\n",
        "        validation_steps = None\n",
        "\n",
        "    history = model.fit(\n",
        "        train_data_generator(train_data_dir, train_mask_dir, train_img_generator, train_mask_generator),\n",
        "        validation_data=val_data_generator if validation_data_dir else None,\n",
        "        validation_steps=validation_steps,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=steps_per_epoch\n",
        "    )\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "qziKNiskSACz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train U-Net\n",
        "history = train_u_net(X_train, y_train, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "id": "jsCUStXJSAIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3: Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "1RzilTlrROyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the U-Net architecture for hyperparameter optimization\n",
        "def u_net_hyperparameter_optimization(input_size, batch_size, loss_function, optimizer):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "\n",
        "    # Decoder\n",
        "    up5 = UpSampling2D((2, 2))(conv4)\n",
        "    concat5 = concatenate([up5, conv3], axis=3)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat5)\n",
        "\n",
        "    up6 = UpSampling2D((2, 2))(conv5)\n",
        "    concat6 = concatenate([up6, conv2], axis=3)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat6)\n",
        "\n",
        "    up7 = UpSampling2D((2, 2))(conv6)\n",
        "    concat7 = concatenate([up7, conv1], axis=3)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat7)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
        "\n",
        "    # Compile the model with the specified hyperparameters\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "FyYUnq0vTIXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the hyperparameters to be evaluated\n",
        "param_grid = {\n",
        "    'batch_size': [8, 16, 32, 64],\n",
        "    'loss_function': [BinaryCrossentropy(), DiceLoss(), JaccardLoss()],\n",
        "    'optimizer': [Adam()]\n",
        "}\n"
      ],
      "metadata": {
        "id": "VpLW-Q1qTIlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search for hyperparameter optimization\n",
        "grid_search = GridSearchCV(estimator=u_net_hyperparameter_optimization, param_grid=param_grid, cv=3)\n",
        "grid_search.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "QZzWRGjATIqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters\n",
        "best_hyperparameters = grid_search.best_params_\n",
        "print(\"Best hyperparameters:\", best_hyperparameters)"
      ],
      "metadata": {
        "id": "FARkhlMHTItF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4: Model Optimization and Fine-Tuning"
      ],
      "metadata": {
        "id": "k-XOwfD-RQxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the U-Net architecture with the best hyperparameters\n",
        "best_model = unet_model_for_hp_optimization(input_size=(256, 256, 3), num_filters=best_num_filters, dropout_rate=best_dropout_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "w0Q7wFCrTvzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "best_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "9FWnPX2BTv9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with the best hyperparameters\n",
        "history = best_model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
        "\n"
      ],
      "metadata": {
        "id": "6O4FTuGCTwCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Visualize training history\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MqS6BeWlTwFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n"
      ],
      "metadata": {
        "id": "2luiiL0kTwIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional Fine-Tuning and Optimization Steps\n",
        "# ...\n",
        "\n",
        "# Save the optimized model for future use\n",
        "best_model.save('optimized_model.h5')\n"
      ],
      "metadata": {
        "id": "c4da9Y84TwLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ChZmhGMTwOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kcVUD-2ZTwrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5: Result Analysis and Application"
      ],
      "metadata": {
        "id": "GWmVfMeBRVcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the optimized model\n",
        "optimized_model = tf.keras.models.load_model('optimized_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "QWF8Qgiua1io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the optimized model on the test set\n",
        "test_loss, test_accuracy = optimized_model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n"
      ],
      "metadata": {
        "id": "slTk5L9-a1o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, make predictions on the test set\n",
        "predictions = optimized_model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "vqUja-F-a1rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform post-processing on predictions if needed\n",
        "# ...\n",
        "\n",
        "# Visualize some test examples with predicted masks\n",
        "visualize_test_examples(X_test, predictions, y_test)\n"
      ],
      "metadata": {
        "id": "Tmgo3TQCa1tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Real-world application\n",
        "# ...\n",
        "\n",
        "# Save the final results or predictions for future reference\n",
        "# ...\n",
        "\n",
        "def visualize_test_examples(X_test, predictions, y_test):\n",
        "    # Implement a visualization function based on your needs\n",
        "    # Display some test examples with the original images, ground truth masks, and predicted masks\n",
        "    # You can use a library like matplotlib for visualization\n",
        "    # ...\n",
        "\n",
        "# Additional Result Analysis and Application Steps\n",
        "# ...\n",
        "\n",
        "# Save final results or predictions for future reference\n",
        "# ...\n",
        "\n",
        "# Real-world application\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "xvCSnE4ra1wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8wiZlA3Ea1zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAGDN93pa11s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}